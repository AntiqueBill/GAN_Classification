{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningDataModule\n",
    "import torch.nn as nn \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class AEDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        #super(self).__init__()\n",
    "        data = h5py.File('./samples/dataset_CNN.mat', 'r')\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            train_x = np.array(data['train_x'])\n",
    "            train_y = np.transpose(data['train_y']) \n",
    "            train_y -= 1\n",
    "\n",
    "            self.train_x = torch.from_numpy(train_x).unsqueeze(1).float()\n",
    "            self.train_y = torch.from_numpy(train_y).squeeze().long()\n",
    "            #self.train_y = F.one_hot(train_y)\n",
    "\n",
    "            print(\"train_x.shape:\", self.train_x.shape)\n",
    "            print(\"train_y.shape:\", self.train_y.shape)\n",
    "        else:\n",
    "            test_x = np.array(data['test_x'])\n",
    "            test_y = np.transpose(data['test_y'])\n",
    "            test_y -= 1 \n",
    "\n",
    "            self.test_x = torch.from_numpy(test_x).unsqueeze(1).float()\n",
    "            self.test_y = torch.from_numpy(test_y).squeeze().long()\n",
    "            #self.test_y = F.one_hot(test_y)\n",
    "\n",
    "            print(\"test_x.shape:\", self.test_x.shape)\n",
    "            print(\"test_y.shape:\", self.test_y.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_x)\n",
    "        else:\n",
    "            return len(self.test_x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            x, y = self.train_x[index], self.train_y[index]\n",
    "        else:\n",
    "            x, y = self.test_x[index], self.test_y[index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "class MyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        train_dataset = AEDataset(train=True)\n",
    "        test_dataset = AEDataset(train=False)\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "class CNNModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 30, 9, 3),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(30, 25, 9, 3),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(25, 20, 9, 3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2160, 512),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(512, 300),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(300, 200),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(200, 120),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(120, 60),\n",
    "        )\n",
    "        #self.features = nn.Linear(60, 40)\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear(60, 6),\n",
    "            #nn.Softmax()\n",
    "            #nn.Sigmoid()\n",
    "        ) \n",
    "            \n",
    "    def forward(self, x):\n",
    "        #called with self(x)\n",
    "        features = self.cnn(x)\n",
    "        output = self.classification(features)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss_fun = nn.CrossEntropyLoss()\n",
    "        loss = loss_fun(y_hat, y)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        loss_fun = nn.CrossEntropyLoss()\n",
    "        loss = loss_fun(y_hat, y)\n",
    "        labels_hat = torch.argmax(y_hat, dim=1)\n",
    "        test_acc = torch.sum(y == labels_hat.int()).item() / (len(y) * 1.0)\n",
    "        test_output = {'test_loss': loss, 'test_acc': test_acc}\n",
    "        return test_output\n",
    "\n",
    "    def test_epoch_end(self, test_step_outputs):\n",
    "        test_epoch_loss = torch.stack([x['loss'] for x in test_output]).mean()\n",
    "        test_epoch_acc = torch.stack([x['acc'] for x in test_output]).mean()\n",
    "        return {\n",
    "            'test_loss': test_epoch_loss,\n",
    "            'log':{'avg_test_loss': test_epoch_loss, 'avg_test_acc': test_epoch_acc}\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.RMSprop(self.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\n\n  | Name           | Type       | Params\n----------------------------------------------\n0 | cnn            | Sequential | 1 M   \n1 | classification | Sequential | 366   \ntrain_x.shape: torch.Size([100, 1, 3000])\ntrain_y.shape: torch.Size([100])\ntest_x.shape: torch.Size([10, 1, 3000])\ntest_y.shape: torch.Size([10])\nEpoch 21:   0%|          | 0/1 [00:00<?, ?it/s]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "model = CNNModel()\n",
    "dm = MyDataModule()\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "# filepath=os.getcwd(),\n",
    "# save_top_k=True,\n",
    "# verbose=True,\n",
    "# monitor='val_loss',\n",
    "# mode='min',\n",
    "# prefix=''\n",
    "# )\n",
    "\n",
    "logger = TensorBoardLogger(\n",
    "save_dir=os.getcwd(),\n",
    "version=1,\n",
    "name='lightning_logs'\n",
    ")\n",
    "trainer = pl.Trainer(gpus=0, logger=logger, max_epochs=1000, min_epochs=10, \n",
    "                     progress_bar_refresh_rate=20)\n",
    "\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python_defaultSpec_1597306698759"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}