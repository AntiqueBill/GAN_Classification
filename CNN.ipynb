{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningDataModule\n",
    "import torch.nn as nn \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import sklearn\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "\n",
    "class AEDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        #super(self).__init__()\n",
    "        data = h5py.File('./samples/dataset_CNN.mat', 'r')\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            train_x = np.array(data['train_x'])\n",
    "            train_y = np.transpose(data['train_y']) \n",
    "            train_y -= 1\n",
    "\n",
    "            self.train_x = torch.from_numpy(train_x).unsqueeze(1).float()\n",
    "            self.train_y = torch.from_numpy(train_y).squeeze().long()\n",
    "            #self.train_y = F.one_hot(train_y)\n",
    "\n",
    "            print(\"train_x.shape:\", self.train_x.shape)\n",
    "            print(\"train_y.shape:\", self.train_y.shape)\n",
    "        else:\n",
    "            test_x = np.array(data['test_x'])\n",
    "            test_y = np.transpose(data['test_y'])\n",
    "            test_y -= 1 \n",
    "\n",
    "            self.test_x = torch.from_numpy(test_x).unsqueeze(1).float()\n",
    "            self.test_y = torch.from_numpy(test_y).squeeze().long()\n",
    "            #self.test_y = F.one_hot(test_y)\n",
    "\n",
    "            print(\"test_x.shape:\", self.test_x.shape)\n",
    "            print(\"test_y.shape:\", self.test_y.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_x)\n",
    "        else:\n",
    "            return len(self.test_x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            x, y = self.train_x[index], self.train_y[index]\n",
    "        else:\n",
    "            x, y = self.test_x[index], self.test_y[index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "class MyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        train_dataset = AEDataset(train=True)\n",
    "        test_dataset = AEDataset(train=False)\n",
    "        N = len(train_dataset)\n",
    "        N_train = int(0.8*N)\n",
    "        N_valid = int(0.2*N)\n",
    "        train, valid = random_split(train_dataset, [N_train, N_valid])\n",
    "        self.train_dataset = train\n",
    "        self.valid_dataset = valid\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=128, shuffle=True)\n",
    "    \n",
    "    def valid_dataloader(self):\n",
    "        return DataLoader(self.valid_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "class CNNModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 30, 9, 3),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(30, 25, 9, 3),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(25, 20, 9, 3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2160, 512),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(512, 300),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(300, 200),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(200, 120),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(120, 60),\n",
    "        )\n",
    "        #self.features = nn.Linear(60, 40)\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear(60, 6),\n",
    "            #nn.Softmax()\n",
    "            #nn.Sigmoid()\n",
    "        ) \n",
    "            \n",
    "    def forward(self, x):\n",
    "        #called with self(x)\n",
    "        features = self.cnn(x)\n",
    "        output = self.classification(features)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss_fun = nn.CrossEntropyLoss()\n",
    "        loss = loss_fun(y_hat, y)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss_fun = nn.CrossEntropyLoss()\n",
    "        loss = loss_fun(y_hat, y)\n",
    "        #labels_hat = torch.argmax(y_hat, dim=1)\n",
    "        test_acc = accuracy(y_hat, y)\n",
    "        test_output = {'test_loss': loss, 'test_acc': test_acc}\n",
    "        return test_output\n",
    "\n",
    "    def test_epoch_end(self, test_step_outputs):\n",
    "        test_epoch_loss = torch.stack([x['test_loss'] for x in test_step_outputs]).mean()\n",
    "        test_epoch_acc = torch.stack([x['test_acc'] for x in test_step_outputs]).mean()\n",
    "        return {\n",
    "            'test_loss': test_epoch_loss,\n",
    "            'log':{'avg_test_loss': test_epoch_loss, 'avg_test_acc': test_epoch_acc}\n",
    "        }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.RMSprop(self.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape: torch.Size([20000, 1, 3000])\n",
      "train_y.shape: torch.Size([20000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | cnn            | Sequential | 1 M   \n",
      "1 | classification | Sequential | 366   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_x.shape: torch.Size([2000, 1, 3000])\n",
      "test_y.shape: torch.Size([2000])\n",
      "Epoch 100:  96%|██████████████████████████████████████████████  | 120/125 [00:01<00:00, 69.55it/s, loss=1.860, v_num=2]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "model = CNNModel()\n",
    "dm = MyDataModule()\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "filepath='./checkpoint',\n",
    "save_top_k=1,\n",
    "#verbose=True,\n",
    "monitor='val_loss',\n",
    "mode='min',\n",
    "#prefix=''\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\n",
    "save_dir=os.getcwd(),\n",
    "version=2,\n",
    "name='lightning_logs'\n",
    ")\n",
    "trainer = pl.Trainer(gpus=1, logger=logger, max_epochs=100, min_epochs=10, checkpoint_callback=checkpoint_callback,\n",
    "                     progress_bar_refresh_rate=20)\n",
    "\n",
    "trainer.fit(model, dm)\n",
    "trainer.save_checkpoint(\"cnn.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 0it [00:00, ?it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_test_acc': tensor(0.1665, device='cuda:0'),\n",
      " 'avg_test_loss': tensor(1.8140, device='cuda:0'),\n",
      " 'test_loss': tensor(1.8140, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing:   0%|                                                                                  | 0/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'avg_test_loss': 1.8140159845352173,\n",
       "  'avg_test_acc': 0.16650390625,\n",
       "  'test_loss': 1.8140159845352173}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_x.shape: torch.Size([2000, 1, 3000])\n",
      "test_y.shape: torch.Size([2000])\n"
     ]
    }
   ],
   "source": [
    "cnn = model.cnn\n",
    "dataset = AEDataset(train=False)\n",
    "test_x = dataset.test_x.cuda()\n",
    "test_y = dataset.test_y.cuda()\n",
    "feature_output = cnn(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-13b8e0438285>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvis_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mplot_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvis_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\Conda\\envs\\TorchLight\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE,MDS\n",
    "\n",
    "feature_output = feature_output \n",
    "test_y = test_y.cpu().detach().numpy() \n",
    "tsne=TSNE()\n",
    "vis_feature=tsne.fit_transform(feature_output) \n",
    "##embedding = MDS(n_components=2)\n",
    "#vis_feature = embedding.fit_transform(np.float32(feature_output))\n",
    "print(vis_feature.shape)\n",
    "\n",
    "plot_feature=np.hstack((vis_feature,test_y))\n",
    "print(plot_feature.shape)\n",
    "\n",
    "colors = tuple([(np.random.random(),np.random.random(), np.random.random()) for i in range(6)])\n",
    "colors = [rgb2hex(x) for x in colors]  # from  matplotlib.colors import  rgb2hex\n",
    "\n",
    "#print(plot_feature[1001])\n",
    "for i, color in enumerate(colors):\n",
    "    #print(i)\n",
    "    need_idx = np.where(test_y_nohot==i)[0]\n",
    "  #print(need_idx)\n",
    "    ax.scatter(vis_feature[need_idx,0],vis_feature[need_idx,1], c=color, label=i)\n",
    "\n",
    "for i, color in enumerate(colors):\n",
    "  #print(i)\n",
    "    need_idx = np.where(test_y_nohot==i)[0]\n",
    "  #print(need_idx)\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.scatter(vis_feature[need_idx,0],vis_feature[need_idx,1], c=color, label=i)\n",
    "    legend2 = ax1.legend(loc='upper right')\n",
    "\n",
    "\n",
    "# 改变坐标轴间隔\n",
    "# x_locator = MultipleLocator(0.01)\n",
    "# y_locator = MultipleLocator(0.01)\n",
    "# ax = plt.gca()\n",
    "# ax.xaxis.set_major_locator(x_locator)\n",
    "# ax.yaxis.set_major_locator(y_locator)\n",
    " \n",
    "legend = ax.legend(loc='upper right')\n",
    "plt.savefig(\"cluster.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TorchLight] *",
   "language": "python",
   "name": "conda-env-TorchLight-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
